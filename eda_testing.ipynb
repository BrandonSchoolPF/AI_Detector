{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Cars. Cars have been around since they became ...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Transportation is a large necessity in most co...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"America's love affair with it's vehicles seem...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>How often do you ride in a car? Do you drive a...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Cars are a wonderful thing. They are perhaps o...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0  Cars. Cars have been around since they became ...    0.0\n",
       "1  Transportation is a large necessity in most co...    0.0\n",
       "2  \"America's love affair with it's vehicles seem...    0.0\n",
       "3  How often do you ride in a car? Do you drive a...    0.0\n",
       "4  Cars are a wonderful thing. They are perhaps o...    0.0"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "\n",
    "df = pd.read_csv('AI_Human.csv')\n",
    "\n",
    "df = df.rename(columns={'generated': 'label'})\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\brand\\OneDrive\\Desktop\\side_projects\\AI_Detector\\venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "c:\\Users\\brand\\OneDrive\\Desktop\\side_projects\\AI_Detector\\venv\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer, BertModel\n",
    "import torch\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "bert = BertModel.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class TextDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer, max_len=256):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        text = self.texts[idx]\n",
    "        label = self.labels[idx]\n",
    "        \n",
    "        encoding = self.tokenizer(\n",
    "            text,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_len,\n",
    "            truncation=True,\n",
    "            padding='max_length',\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        \n",
    "        return {\n",
    "            'input_ids': encoding['input_ids'].squeeze(),   # shape: [max_len]\n",
    "            'attention_mask': encoding['attention_mask'].squeeze(),  # shape: [max_len]\n",
    "            'label': torch.tensor(label, dtype=torch.float)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_texts, val_texts, train_labels, val_labels = train_test_split(\n",
    "    df['text'].tolist(),\n",
    "    df['label'].tolist(),\n",
    "    test_size=0.2,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "train_dataset = TextDataset(train_texts, train_labels, tokenizer)\n",
    "val_dataset = TextDataset(val_texts, val_labels, tokenizer)\n",
    "subset = torch.utils.data.Subset(train_dataset, range(1000))\n",
    "train_loader = DataLoader(subset, batch_size=32, shuffle=False)\n",
    "val_subset = torch.utils.data.Subset(val_dataset, range(500))  # use first 500 samples\n",
    "val_loader = DataLoader(val_subset, batch_size=128)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class BertClassifier(nn.Module):\n",
    "    def __init__(self, bert_model, hidden_size=768):\n",
    "        super(BertClassifier, self).__init__()\n",
    "        self.bert = bert_model\n",
    "        self.classifier = nn.Linear(hidden_size, 1)  # output 1 for binary classification\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        pooled_output = outputs.pooler_output  # [batch_size, hidden_size]\n",
    "        logits = self.classifier(pooled_output)\n",
    "        return self.sigmoid(logits)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch_directml\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "dml = torch_directml.device()\n",
    "\n",
    "model = BertClassifier(bert).to(device)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=2e-5)\n",
    "criterion = nn.BCELoss()  # Binary Cross-Entropy for boolean labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm  # for progress bars\n",
    "\n",
    "def train_model(model, dataloader, optimizer, criterion, device='cpu', epochs=3):\n",
    "    model.train()  # set to training mode\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0\n",
    "\n",
    "        for batch in tqdm(dataloader, desc=f\"Epoch {epoch+1}/{epochs}\"):\n",
    "            # 1️⃣ Move data to device\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['label'].to(device).float()  # shape [batch_size]\n",
    "\n",
    "            # 2️⃣ Forward pass\n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "            outputs = outputs.squeeze()  # remove [batch_size, 1] -> [batch_size]\n",
    "\n",
    "            # 3️⃣ Compute loss\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            # 4️⃣ Backward pass and optimization\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        avg_loss = total_loss / len(dataloader)\n",
    "        print(f\"Epoch {epoch+1} | Average Loss: {avg_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/3: 100%|██████████| 32/32 [07:14<00:00, 13.59s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 | Average Loss: 0.4678\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/3: 100%|██████████| 32/32 [07:10<00:00, 13.46s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 | Average Loss: 0.1693\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/3: 100%|██████████| 32/32 [07:11<00:00, 13.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 | Average Loss: 0.0660\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_model(model, train_loader, optimizer, criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6120\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Make sure model is in evaluation mode\n",
    "model.eval()\n",
    "\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in val_loader:\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['label'].to(device)\n",
    "        \n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        \n",
    "        # If your model returns logits\n",
    "        preds = torch.argmax(outputs, dim=1)\n",
    "        \n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "# Compute accuracy\n",
    "acc = accuracy_score(all_labels, all_preds)\n",
    "print(f'Validation Accuracy: {acc:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_text(text, model, tokenizer, max_len=256, device='cpu'): #Change device param if you want either CPU or CUDA (Nvidia GPU)\n",
    "    # Move model to device\n",
    "    model.to(device)\n",
    "\n",
    "    # Tokenize the text\n",
    "    encoding = tokenizer(\n",
    "        text,\n",
    "        add_special_tokens=True,\n",
    "        max_length=max_len,\n",
    "        truncation=True,\n",
    "        padding='max_length',\n",
    "        return_tensors='pt'\n",
    "    )\n",
    "\n",
    "    input_ids = encoding['input_ids'].to(device)\n",
    "    attention_mask = encoding['attention_mask'].to(device)\n",
    "\n",
    "    # Make prediction\n",
    "    with torch.no_grad():\n",
    "        output = model(input_ids, attention_mask)\n",
    "        prediction = (output.item() > 0.5)\n",
    "        print(f\"Model predicts that this text is {output.item():.2%} AI generated\")\n",
    "    return \"AI\" if prediction else \"Human\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model predicts that this text is 93.57% AI generated\n",
      "AI\n"
     ]
    }
   ],
   "source": [
    "text = \"\"\"\n",
    "\n",
    "The J.M. Smucker Co. is suing Trader Joe’s, alleging the grocery chain’s new frozen peanut butter and jelly sandwiches are too similar to Smucker’s Uncrustables in their design and packaging.\n",
    "\n",
    "In the lawsuit, which was filed Monday in federal court in Ohio, Smucker said the round, crustless sandwiches Trader Joe’s sells have the same pie-like crimp markings on their edges that Uncrustables do. Smucker said the design violates its trademarks.\n",
    "\n",
    "Smucker also asserted that the boxes Trader Joe’s PB&J sandwiches come in violate the Orrville, Ohio-based company’s trademarks because they are the same blue color it uses for the lettering on “Uncrustables” packages.\n",
    "\n",
    "Trader Joe’s boxes also show a sandwich with a bite mark taken out of it, which is similar to the Uncrustables design, Smucker said.\n",
    "\"\"\"\n",
    "\n",
    "result = predict_text(text, model, tokenizer)  # or 'cpu'\n",
    "print(result)  # Output: \"AI\" or \"Human\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_model(model, validation_loader, criterion, device):\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "    total_loss = 0\n",
    "    correct_predictions = 0\n",
    "    total_samples = 0\n",
    "\n",
    "    with torch.no_grad():  # Disable gradient calculations\n",
    "        for inputs, labels in validation_loader:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            # Example for classification accuracy\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total_samples += labels.size(0)\n",
    "            correct_predictions += (predicted == labels).sum().item()\n",
    "\n",
    "    avg_loss = total_loss / len(validation_loader)\n",
    "    accuracy = (correct_predictions / total_samples) * 100\n",
    "\n",
    "    print(f\"Validation Loss: {avg_loss:.4f}, Validation Accuracy: {accuracy:.2f}%\")\n",
    "    model.train()  # Set model back to training mode if needed\n",
    "    return avg_loss, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'validation_loader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m validate_model(model, \u001b[43mvalidation_loader\u001b[49m, criterion, \u001b[33m'\u001b[39m\u001b[33mcpu\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'validation_loader' is not defined"
     ]
    }
   ],
   "source": [
    "validate_model(model, validation_loader, criterion, 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
